{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2lQ2Jtq8Fz8g"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "mount_file_id": "1RRLzG_U9-gsZggvkbbv_ran_z_jQzG4-",
      "authorship_tag": "ABX9TyNAju1+WOdM6oWdLMWHRwYs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ichiyan/brain-decoding/blob/master/vdvae_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation Set-Up\n",
        "\n",
        "\n",
        "*   Clone repo\n",
        "*   Install dependencies\n",
        "*   Import hps\n",
        "*   Copy imagenet64 checkpoints\n",
        "*   Copy NSD data\n",
        "*   .\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qbash1dvD90H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWKvkKtQ_zke",
        "outputId": "600db2d3-c5dc-4ab0-d15f-5f20ea4cc9d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'brain-decoding'...\n",
            "remote: Enumerating objects: 337, done.\u001b[K\n",
            "remote: Counting objects: 100% (337/337), done.\u001b[K\n",
            "remote: Compressing objects: 100% (260/260), done.\u001b[K\n",
            "remote: Total 337 (delta 72), reused 316 (delta 58), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (337/337), 13.19 MiB | 7.66 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ichiyan/brain-decoding.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHVj33bK-Gks",
        "outputId": "6723b3d2-fd1c-47bc-c755-2e08e6b0719d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Zl0spf7FD4y_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb29be6-3c9b-4a06-894f-921347712181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mpi4py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbRvVFW1A4b9",
        "outputId": "74486068-cf8b-4711-da28-c6665b54661c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.5.tar.gz (2.5 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/2.5 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.5-cp310-cp310-linux_x86_64.whl size=2746525 sha256=879861e396213ebad1628e5ada87dc81fcce006e2270d22362d98e435465d94b\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/2b/7f/c852523089e9182b45fca50ff56f49a51eeb6284fd25a66713\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/brain-decoding/vdvae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEbSZVtguAkA",
        "outputId": "c02bf65c-7206-4708-a022-49e68929a60f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/brain-decoding/vdvae\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert the directory\n",
        "import sys\n",
        "sys.path.insert(0,'/content/brain-decoding/vdvae')"
      ],
      "metadata": {
        "id": "B5qyP7o3Eg-Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hps import Hyperparams, parse_args_and_update_hparams, add_vae_arguments\n",
        "add_vae_arguments"
      ],
      "metadata": {
        "id": "2MhVZEcVFIsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7de5f98-a783-4179-8833-391d1bfc3146"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function hps.add_vae_arguments(parser)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  CUDA"
      ],
      "metadata": {
        "id": "e6SEiyIY3p4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MkOLZtH1DBC",
        "outputId": "80b08ca4-df37-4bcf-9077-feac208242bf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Picking GPU if available or else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "device = get_default_device()"
      ],
      "metadata": {
        "id": "Z11y2QgI1MJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)"
      ],
      "metadata": {
        "id": "JKOUcwFm1j8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Nu2C-9aE9566",
        "outputId": "40783ec2-9a49-4ab0-ad85-e61b294d94fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Testingting VDVAE"
      ],
      "metadata": {
        "id": "khkMSD_k3vJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/brain-decoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaPpDtxKxz7Q",
        "outputId": "7f185d7c-be5c-4d58-8f6d-b6d155808f01"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/brain-decoding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/latest/vdvae_extract_features.py -sub 1"
      ],
      "metadata": {
        "id": "Um6F4g0Nx2Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/latest/vdvae_extract_depth_features_v2.py -sub 1"
      ],
      "metadata": {
        "id": "lUE5qIcD0Dp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/latest/vdvae_regression.py -sub 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04LJhCL71u0-",
        "outputId": "09d2f16d-15d4-4d9f-9587-035588a7d41a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-4.8202814e-08 0.9999432\n",
            "-0.027261836 0.99147815\n",
            "24.480553 -14.412728\n",
            "9.81828 -9.315342\n",
            "Training latents Feature Regression\n",
            "-0.013801442226305444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/latest/vdvae_regression_depth_v2.py -sub 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzTDyV_d1vgn",
        "outputId": "b17e03b2-6324-4d34-f2b8-76ae2839ffb9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-4.8202814e-08 0.9999432\n",
            "-0.027261836 0.99147815\n",
            "24.480553 -14.412728\n",
            "9.81828 -9.315342\n",
            "Training latents Feature Regression\n",
            "-0.013829342668076868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/latest/vdvae_reconstruct_images.py -sub 1"
      ],
      "metadata": {
        "id": "LwJG61_y1wOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/latest/vdvae_reconstruct_depth_images_v2.py -sub 1"
      ],
      "metadata": {
        "id": "7GQjI8_d1xAC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83dd7207-ce09-44c8-d588-0a025e502fb0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libs imported\n",
            "Models Loading\n",
            "Restoring ema vae from vdvae/model/imagenet64-iter-1600000-model-ema.th\n",
            "0\n",
            "30\n",
            "60\n",
            "90\n",
            "120\n",
            "150\n",
            "180\n",
            "210\n",
            "240\n",
            "270\n",
            "300\n",
            "330\n",
            "360\n",
            "390\n",
            "420\n",
            "450\n",
            "480\n",
            "510\n",
            "540\n",
            "570\n",
            "600\n",
            "630\n",
            "660\n",
            "690\n",
            "720\n",
            "750\n",
            "780\n",
            "810\n",
            "840\n",
            "870\n",
            "900\n",
            "930\n",
            "960\n",
            "0\n",
            "30\n",
            "60\n",
            "90\n",
            "120\n",
            "150\n",
            "180\n",
            "210\n",
            "240\n",
            "270\n",
            "300\n",
            "330\n",
            "360\n",
            "390\n",
            "420\n",
            "450\n",
            "480\n",
            "510\n",
            "540\n",
            "570\n",
            "600\n",
            "630\n",
            "660\n",
            "690\n",
            "720\n",
            "750\n",
            "780\n",
            "810\n",
            "840\n",
            "870\n",
            "900\n",
            "930\n",
            "960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COPY FILES TO DRIVE"
      ],
      "metadata": {
        "id": "kEZp0Dp4Tk1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images\n",
        "\n"
      ],
      "metadata": {
        "id": "E1IvgiMScqvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cp /content/brain-decoding/results/vdvae/subj01/stim_47l/115.png /content/drive/MyDrive/brain_decoding/data/reconstructed/47l\n",
        "cp /content/brain-decoding/results/vdvae/subj01/stim_47l/25.png /content/drive/MyDrive/brain_decoding/data/reconstructed/47l\n",
        "cp /content/brain-decoding/results/vdvae/subj01/stim_47l/451.png /content/drive/MyDrive/brain_decoding/data/reconstructed/47l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8GFGR6NNpgN",
        "outputId": "2eff89d4-22e7-496a-b88e-5a91b3ce01ce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/results/vdvae/subj01/stim_47l /content/drive/MyDrive/brain_decoding/data/reconstructed/47l"
      ],
      "metadata": {
        "id": "JmANR2J-Uens"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depth"
      ],
      "metadata": {
        "id": "2mTwffIOcwFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cp /content/brain-decoding/results/vdvae/subj01/depth_stim_43l/115.png /content/drive/MyDrive/brain_decoding/data/reconstructed/41l-depth\n",
        "cp /content/brain-decoding/results/vdvae/subj01/depth_stim_43l/25.png /content/drive/MyDrive/brain_decoding/data/reconstructed/41l-depth\n",
        "cp /content/brain-decoding/results/vdvae/subj01/depth_stim_43l/451.png /content/drive/MyDrive/brain_decoding/data/reconstructed/41l-depth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt9OrRBIcZh7",
        "outputId": "e391473d-566a-48aa-81ce-17dea7490e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/results/vdvae/subj01/depth_stim_43l /content/drive/MyDrive/brain_decoding/data/reconstructed/41l-depth"
      ],
      "metadata": {
        "id": "rTlMc3VocMtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracted Features"
      ],
      "metadata": {
        "id": "ddrl6zVVahyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/data/extracted_features/subj01/nsd_vdvae_depth_features_47l.npz /content/drive/MyDrive/brain_decoding/data"
      ],
      "metadata": {
        "id": "-YeCtbHRZCOe"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicted Features"
      ],
      "metadata": {
        "id": "Lq6oZPThamKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/data/predicted_features/subj01/nsd_vdvae_depth_nsdgeneral_pred_sub1_47l_alpha100k.npy /content/drive/MyDrive/brain_decoding/data"
      ],
      "metadata": {
        "id": "WLLVfdTuafnF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ShwF3miUo-h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import & downloads"
      ],
      "metadata": {
        "id": "5YoZNlQXxXGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-colab-shell"
      ],
      "metadata": {
        "id": "wW6ji4YQeQ1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing python files from github"
      ],
      "metadata": {
        "id": "5XV6iodCElZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from google_colab_shell import getshell\n",
        "# os.system('/content/brain-decoding/vdvae/setup_cifar10.sh')\n",
        "# os.system('/content/brain-decoding/vdvae/setup_ffhq1024.sh')\n",
        "# os.system('/content/brain-decoding/vdvae/setup_ffhq256.sh')\n",
        "# os.system('/content/brain-decoding/vdvae/setup_imagenet.sh')"
      ],
      "metadata": {
        "id": "Jlt5cPLvaama"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "bash /content/brain-decoding/vdvae/setup_cifar10.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfwy2lHBfH2a",
        "outputId": "f13fe80c-0e4f-478f-b078-afa9cdb87bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-28 00:28:12--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  14.0MB/s    in 13s     \n",
            "\n",
            "2023-10-28 00:28:26 (12.4 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/cifar-10-python.tar.gz /content/brain-decoding/vdvae/model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThOfA6rdzY_s",
        "outputId": "5f525592-6b72-48ab-e23b-ee0ee1061ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/cifar-10-python.tar.gz': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%shell\n",
        "# bash /content/brain-decoding/vdvae/setup_imagenet.sh -imagenet64"
      ],
      "metadata": {
        "id": "rXuPFvGVfdTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir train\n",
        "# cp /content/brain-decoding/vdvae/train.py /content/train.py"
      ],
      "metadata": {
        "id": "vcdNjFczh4aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/brain-decoding/vdvae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plpjiOuHjqCi",
        "outputId": "2e600620-f57e-4e21-f2b9-03508cbc85ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/brain-decoding/vdvae\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>ImageNet 64</h3>"
      ],
      "metadata": {
        "id": "waxSILPuBbbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# 125M parameter model, trained for 1.6M iters (about 2.5 weeks on 32 V100)\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/imagenet64-iter-1600000-log.jsonl\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/imagenet64-iter-1600000-model.th\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/imagenet64-iter-1600000-model-ema.th\n",
        "# should be 2.44 nats, or 3.52 bits per dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S66MhH9cghba",
        "outputId": "d1f48ad5-b181-46c0-f492-d281eb761e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-28 00:28:28--  https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/imagenet64-iter-1600000-log.jsonl\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.150.77.132\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.150.77.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 145115 (142K) [application/octet-stream]\n",
            "Saving to: ‘imagenet64-iter-1600000-log.jsonl’\n",
            "\n",
            "imagenet64-iter-160 100%[===================>] 141.71K   173KB/s    in 0.8s    \n",
            "\n",
            "2023-10-28 00:28:30 (173 KB/s) - ‘imagenet64-iter-1600000-log.jsonl’ saved [145115/145115]\n",
            "\n",
            "--2023-10-28 00:28:30--  https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/imagenet64-iter-1600000-model.th\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.150.77.132\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.150.77.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 501006513 (478M) [text/plain]\n",
            "Saving to: ‘imagenet64-iter-1600000-model.th’\n",
            "\n",
            "imagenet64-iter-160 100%[===================>] 477.80M  9.86MB/s    in 56s     \n",
            "\n",
            "2023-10-28 00:29:27 (8.52 MB/s) - ‘imagenet64-iter-1600000-model.th’ saved [501006513/501006513]\n",
            "\n",
            "--2023-10-28 00:29:27--  https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/imagenet64-iter-1600000-model-ema.th\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.150.77.132\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.150.77.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 500977841 (478M) [text/plain]\n",
            "Saving to: ‘imagenet64-iter-1600000-model-ema.th’\n",
            "\n",
            "imagenet64-iter-160 100%[===================>] 477.77M  10.1MB/s    in 59s     \n",
            "\n",
            "2023-10-28 00:30:27 (8.08 MB/s) - ‘imagenet64-iter-1600000-model-ema.th’ saved [500977841/500977841]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/imagenet64-iter-1600000-opt.th\n",
        "python train.py --hps imagenet64 --restore_path imagenet64-iter-1600000-model.th --restore_ema_path imagenet64-iter-1600000-model-ema.th --restore_log_path imagenet64-iter-1600000-log.jsonl --restore_optimizer_path imagenet64-iter-1600000-opt.th --test_eval\n",
        "# should be 2.44 nats, or 3.52 bits per dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "lBgq4L07l5Mc",
        "outputId": "ab3c624d-26c5-4eeb-b5f8-deaa725f907e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-28 00:30:27--  https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/imagenet64-iter-1600000-opt.th\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.150.77.132\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.150.77.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1001616051 (955M) [text/plain]\n",
            "Saving to: ‘imagenet64-iter-1600000-opt.th’\n",
            "\n",
            "imagenet64-iter-160 100%[===================>] 955.21M  10.5MB/s    in 1m 45s  \n",
            "\n",
            "2023-10-28 00:32:13 (9.14 MB/s) - ‘imagenet64-iter-1600000-opt.th’ saved [1001616051/1001616051]\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/brain-decoding/vdvae/train.py\", line 9, in <module>\n",
            "    from utils import get_cpu_stats_over_ranks\n",
            "  File \"/content/brain-decoding/vdvae/utils.py\", line 1, in <module>\n",
            "    from mpi4py import MPI\n",
            "ModuleNotFoundError: No module named 'mpi4py'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2415ab117023>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/imagenet64-iter-1600000-opt.th\\npython train.py --hps imagenet64 --restore_path imagenet64-iter-1600000-model.th --restore_ema_path imagenet64-iter-1600000-model-ema.th --restore_log_path imagenet64-iter-1600000-log.jsonl --restore_optimizer_path imagenet64-iter-1600000-opt.th --test_eval\\n# should be 2.44 nats, or 3.52 bits per dim\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/imagenet64-iter-1600000-opt.th\npython train.py --hps imagenet64 --restore_path imagenet64-iter-1600000-model.th --restore_ema_path imagenet64-iter-1600000-model-ema.th --restore_log_path imagenet64-iter-1600000-log.jsonl --restore_optimizer_path imagenet64-iter-1600000-opt.th --test_eval\n# should be 2.44 nats, or 3.52 bits per dim\n' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copying IMAGENET64 files from drive to repo dir"
      ],
      "metadata": {
        "id": "yWTF75tw20PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cp /content/drive/MyDrive/brain_decoding/data/vdvae/imagenet64-iter-1600000-log.jsonl /content/brain-decoding/vdvae/model/imagenet64-iter-1600000-log.jsonl"
      ],
      "metadata": {
        "id": "WMTM64tG11_a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp /content/drive/MyDrive/brain_decoding/data/vdvae/imagenet64-iter-1600000-model-ema.th /content/brain-decoding/vdvae/model/imagenet64-iter-1600000-model-ema.th"
      ],
      "metadata": {
        "id": "0pjlZ9Ae1-en"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp /content/drive/MyDrive/brain_decoding/data/vdvae/imagenet64-iter-1600000-model.th /content/brain-decoding/vdvae/model/imagenet64-iter-1600000-model.th"
      ],
      "metadata": {
        "id": "MkiY7mGG2Ci0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp /content/drive/MyDrive/brain_decoding/data/vdvae/imagenet64-iter-1600000-opt.th /content/brain-decoding/vdvae/model/imagenet64-iter-1600000-opt.thz"
      ],
      "metadata": {
        "id": "CRkPkoc71Ahd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other datasets"
      ],
      "metadata": {
        "id": "nOURQD3x27CT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>FFHQ-256</h3>"
      ],
      "metadata": {
        "id": "ns8sm8nX3Iwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/brain-decoding/vdvae"
      ],
      "metadata": {
        "id": "wOaO1EAU6ovo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "bash /content/brain-decoding/vdvae/setup_ffhq256.sh"
      ],
      "metadata": {
        "id": "1nOhZ5q-EB73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# 115M parameters, trained for 1.7M iterations (or about 2.5 weeks) on 32 V100\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets/ffhq256-iter-1700000-log.jsonl\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets/ffhq256-iter-1700000-model.th\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets/ffhq256-iter-1700000-model-ema.th\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets/ffhq256-iter-1700000-opt.th\n",
        "python train.py --hps ffhq256 --restore_path ffhq256-iter-1700000-model.th --restore_ema_path ffhq256-iter-1700000-model-ema.th --restore_log_path ffhq256-iter-1700000-log.jsonl --restore_optimizer_path ffhq256-iter-1700000-opt.th --test_eval\n",
        "# should be 0.4232 nats, or 0.61 bits per dim"
      ],
      "metadata": {
        "id": "2XAgBAT5wpxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/vdvae/ffhq256-iter-1700000-log.jsonl /content/brain-decoding/vdvae/model"
      ],
      "metadata": {
        "id": "Bt66H2El8zNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/vdvae/ffhq256-iter-1700000-model-ema.th /content/brain-decoding/vdvae/model"
      ],
      "metadata": {
        "id": "oV57LZ-487t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/vdvae/ffhq256-iter-1700000-model.th /content/brain-decoding/vdvae/model"
      ],
      "metadata": {
        "id": "LJ7G_Qnr88Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/vdvae/ffhq256-iter-1700000-opt.th /content/brain-decoding/vdvae/model"
      ],
      "metadata": {
        "id": "tcWDow0R88jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>FFHQ-1024</h3>"
      ],
      "metadata": {
        "id": "YHqx6b_53ecN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "bash /content/brain-decoding/vdvae/setup_ffhq1024.sh"
      ],
      "metadata": {
        "id": "NFb4PJH4JP4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# 115M parameters, trained for 1.7M iterations (or about 2.5 weeks) on 32 V100\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets/ffhq1024-iter-1700000-log.jsonl\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets/ffhq1024-iter-1700000-model.th\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets/ffhq1024-iter-1700000-model-ema.th\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets/ffhq1024-iter-1700000-opt.th\n",
        "python train.py --hps ffhq1024 --restore_path ffhq1024-iter-1700000-model.th --restore_ema_path ffhq1024-iter-1700000-model-ema.th --restore_log_path ffhq1024-iter-1700000-log.jsonl --restore_optimizer_path ffhq1024-iter-1700000-opt.th --test_eval\n",
        "# should be 1.678 nats, or 2.42 bits per dim"
      ],
      "metadata": {
        "id": "s2VSnjYi3h_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/vdvae/ffhq1024-iter-1700000-log.jsonl /content/brain-decoding/vdvae/model"
      ],
      "metadata": {
        "id": "L2aCdkd8QtaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/vdvae/ffhq1024-iter-1700000-model-ema.th"
      ],
      "metadata": {
        "id": "4WZBfqbPQuyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/vdvae/ffhq1024-iter-1700000-model.th /content/brain-decoding/vdvae/model"
      ],
      "metadata": {
        "id": "ajNHl8NlQv0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/vdvae/ffhq1024-iter-1700000-opt.th /content/brain-decoding/vdvae/model"
      ],
      "metadata": {
        "id": "Nrh_Ep7YQwUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>CIFAR-10 </h3>"
      ],
      "metadata": {
        "id": "VAFpgaOH5FTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "bash /content/brain-decoding/vdvae/setup_cifar10.sh"
      ],
      "metadata": {
        "id": "UfswITa5Q06j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MsRv4QAkrzEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# 39M parameters, trained for ~1M iterations with early stopping (a little less than a week on 2 GPUs)\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/cifar10-seed0-iter-900000-model-ema.th\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/cifar10-seed1-iter-1050000-model-ema.th\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/cifar10-seed2-iter-650000-model-ema.th\n",
        "wget https://openaipublic.blob.core.windows.net/very-deep-vaes-assets/vdvae-assets-2/cifar10-seed3-iter-1050000-model-ema.th\n",
        "python train.py --hps cifar10 --restore_ema_path cifar10-seed0-iter-900000-model-ema.th --test_eval\n",
        "python train.py --hps cifar10 --restore_ema_path cifar10-seed1-iter-1050000-model-ema.th --test_eval\n",
        "python train.py --hps cifar10 --restore_ema_path cifar10-seed2-iter-650000-model-ema.th --test_eval\n",
        "python train.py --hps cifar10 --restore_ema_path cifar10-seed3-iter-1050000-model-ema.th --test_eval\n",
        "# seeds 0, 1, 2, 3 should give 2.879, 2.842, 2.898, 2.864 bits per dim, for an average of 2.87 bits per dim."
      ],
      "metadata": {
        "id": "-t_qLYIm5Fyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/vdvae/cifar10-seed0-iter-900000-model-ema.th /content/brain-decoding/vdvae/model"
      ],
      "metadata": {
        "id": "Yr_66uBOn7rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/vdvae/cifar10-seed1-iter-1050000-model-ema.th /content/brain-decoding/vdvae/model"
      ],
      "metadata": {
        "id": "93BsXEG8r_FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/vdvae/cifar10-seed2-iter-650000-model-ema.th /content/brain-decoding/vdvae/model"
      ],
      "metadata": {
        "id": "4U3RaW0NsAdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/brain-decoding/vdvae/cifar10-seed3-iter-1050000-model-ema.th /content/brain-decoding/vdvae/model"
      ],
      "metadata": {
        "id": "XuZqCwjssBj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move NSD files to repo dir"
      ],
      "metadata": {
        "id": "otkEhvi93iim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "/content/brain-decoding/data/processed_data"
      ],
      "metadata": {
        "id": "Cc-6XDaf31VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cp /content/drive/MyDrive/brain_decoding/data/fMRI/NSD/nsd_test_cap_sub1.npy /content/brain-decoding/data/processed_data/subj01/nsd_test_cap_sub1.npy\n",
        "cp /content/drive/MyDrive/brain_decoding/data/fMRI/NSD/nsd_test_depth_stim_sub1.npy /content/brain-decoding/data/processed_data/subj01/nsd_test_depth_stim_sub1.npy\n",
        "cp /content/drive/MyDrive/brain_decoding/data/fMRI/NSD/nsd_test_fmriavg_nsdgeneral_sub1.npy /content/brain-decoding/data/processed_data/subj01/nsd_test_fmriavg_nsdgeneral_sub1.npy\n",
        "cp /content/drive/MyDrive/brain_decoding/data/fMRI/NSD/nsd_test_stim_sub1.npy /content/brain-decoding/data/processed_data/subj01/nsd_test_stim_sub1.npy\n",
        "cp /content/drive/MyDrive/brain_decoding/data/fMRI/NSD/nsd_train_cap_sub1.npy /content/brain-decoding/data/processed_data/subj01/nsd_train_cap_sub1.npy\n",
        "cp /content/drive/MyDrive/brain_decoding/data/fMRI/NSD/nsd_train_depth_stim_sub1.npy /content/brain-decoding/data/processed_data/subj01/nsd_train_depth_stim_sub1.npy\n",
        "cp /content/drive/MyDrive/brain_decoding/data/fMRI/NSD/nsd_train_fmriavg_nsdgeneral_sub1.npy /content/brain-decoding/data/processed_data/subj01/nsd_train_fmriavg_nsdgeneral_sub1.npy\n",
        "cp /content/drive/MyDrive/brain_decoding/data/fMRI/NSD/nsd_train_stim_sub1.npy /content/brain-decoding/data/processed_data/subj01/nsd_train_stim_sub1.npy"
      ],
      "metadata": {
        "id": "zJQWdF5wuUB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76615e37-0d3a-4ea8-ace5-ec4a793dd38a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/brain-decoding"
      ],
      "metadata": {
        "id": "ypcZ_VbgsbF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VDVAE Extract Features"
      ],
      "metadata": {
        "id": "2lQ2Jtq8Fz8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('vdvae')\n",
        "import torch\n",
        "import numpy as np\n",
        "#from mpi4py import MPI\n",
        "import socket\n",
        "import argparse\n",
        "import os\n",
        "import json\n",
        "import subprocess\n",
        "from utils import (logger,\n",
        "                   local_mpi_rank,\n",
        "                   mpi_size,\n",
        "                   maybe_download,\n",
        "                   mpi_rank)\n",
        "from data import mkdir_p\n",
        "from contextlib import contextmanager\n",
        "import torch.distributed as dist\n",
        "#from apex.optimizers import FusedAdam as AdamW\n",
        "from vae import VAE\n",
        "from torch.nn.parallel.distributed import DistributedDataParallel\n",
        "from train_helpers import restore_params\n",
        "from image_utils import *\n",
        "from model_utils import *\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import pickle"
      ],
      "metadata": {
        "id": "ai2IDTOCBkji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse"
      ],
      "metadata": {
        "id": "DC87A7_wMN7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser(description='Argument Parser')\n",
        "parser.add_argument(\"-sub\", \"--sub\",help=\"Subject Number\",default=1)\n",
        "parser.add_argument(\"-bs\", \"--bs\",help=\"Batch Size\",default=30)\n",
        "args = parser.parse_args(\"\")"
      ],
      "metadata": {
        "id": "NuBYk2fGMbwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub=int(args.sub)\n",
        "assert sub in [1,2,5,7]\n",
        "batch_size=int(args.bs)\n",
        "\n",
        "print('Libs imported')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XRgEqGjCG84",
        "outputId": "26340ff6-17f1-42d7-b80f-208a6b0dc076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libs imported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H = {'image_size': 64, 'image_channels': 3,'seed': 0, 'port': 29500, 'save_dir': './saved_models/test', 'data_root': './', 'desc': 'test', 'hparam_sets': 'imagenet64', 'restore_path': 'imagenet64-iter-1600000-model.th', 'restore_ema_path': 'vdvae/model/imagenet64-iter-1600000-model-ema.th', 'restore_log_path': 'imagenet64-iter-1600000-log.jsonl', 'restore_optimizer_path': 'imagenet64-iter-1600000-opt.th', 'dataset': 'imagenet64', 'ema_rate': 0.999, 'enc_blocks': '64x11,64d2,32x20,32d2,16x9,16d2,8x8,8d2,4x7,4d4,1x5', 'dec_blocks': '1x2,4m1,4x3,8m4,8x7,16m8,16x15,32m16,32x31,64m32,64x12', 'zdim': 16, 'width': 512, 'custom_width_str': '', 'bottleneck_multiple': 0.25, 'no_bias_above': 64, 'scale_encblock': False, 'test_eval': True, 'warmup_iters': 100, 'num_mixtures': 10, 'grad_clip': 220.0, 'skip_threshold': 380.0, 'lr': 0.00015, 'lr_prior': 0.00015, 'wd': 0.01, 'wd_prior': 0.0, 'num_epochs': 10000, 'n_batch': 4, 'adam_beta1': 0.9, 'adam_beta2': 0.9, 'temperature': 1.0, 'iters_per_ckpt': 25000, 'iters_per_print': 1000, 'iters_per_save': 10000, 'iters_per_images': 10000, 'epochs_per_eval': 1, 'epochs_per_probe': None, 'epochs_per_eval_save': 1, 'num_images_visualize': 8, 'num_variables_visualize': 6, 'num_temperatures_visualize': 3, 'mpi_size': 1, 'local_rank': 0, 'rank': 0, 'logdir': './saved_models/test/log'}\n",
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "H = dotdict(H)\n",
        "\n",
        "H, preprocess_fn = set_up_data(H)\n",
        "\n",
        "print('Models Loading')\n",
        "ema_vae = load_vaes(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZA0MnxlC6nV",
        "outputId": "1bd9a5fd-6d9d-413a-cc44-4abdce4f7d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models Loading\n",
            "Restoring ema vae from vdvae/model/imagenet64-iter-1600000-model-ema.th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class batch_generator_external_images(Dataset):\n",
        "\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        self.im = np.load(data_path).astype(np.uint8)\n",
        "\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        img = Image.fromarray(self.im[idx])\n",
        "        img = T.functional.resize(img,(64,64))\n",
        "        img = torch.tensor(np.array(img)).float()\n",
        "        #img = img/255\n",
        "        #img = img*2 - 1\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return  len(self.im)"
      ],
      "metadata": {
        "id": "2d972qAXDgJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = 'data/processed_data/subj{:02d}/nsd_train_stim_sub{}.npy'.format(sub,sub)\n",
        "train_images = batch_generator_external_images(data_path = image_path)\n",
        "\n",
        "image_path = 'data/processed_data/subj{:02d}/nsd_test_stim_sub{}.npy'.format(sub,sub)\n",
        "test_images = batch_generator_external_images(data_path = image_path)\n",
        "\n",
        "trainloader = DataLoader(train_images,batch_size,shuffle=False)\n",
        "testloader = DataLoader(test_images,batch_size,shuffle=False)"
      ],
      "metadata": {
        "id": "cxGLTp_2Dkca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#expand error message\n",
        "%tb"
      ],
      "metadata": {
        "id": "bc2xU2tUTYwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Latents </h3>"
      ],
      "metadata": {
        "id": "s9QVGkRWD9Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# num_latents = 41\n",
        "num_latents = 41\n",
        "test_latents = []"
      ],
      "metadata": {
        "id": "jMHs8qbeD6SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,x in enumerate(testloader):\n",
        "  data_input, target = preprocess_fn(x)\n",
        "  with torch.no_grad():\n",
        "        print(i*batch_size)\n",
        "        activations = ema_vae.encoder.forward(data_input)\n",
        "        px_z, stats = ema_vae.decoder.forward(activations, get_latents=True)\n",
        "        #recons = ema_vae.decoder.out_net.sample(px_z)\n",
        "        batch_latent = []\n",
        "        for i in range(num_latents):\n",
        "            #test_latents[i].append(stats[i]['z'].cpu().numpy())\n",
        "            batch_latent.append(stats[i]['z'].cpu().numpy().reshape(len(data_input),-1))\n",
        "        test_latents.append(np.hstack(batch_latent))\n",
        "\n",
        "test_latents = np.concatenate(test_latents)"
      ],
      "metadata": {
        "id": "r3Xc40KvEEww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_latents = []\n",
        "for i,x in enumerate(trainloader):\n",
        "  data_input, target = preprocess_fn(x)\n",
        "  with torch.no_grad():\n",
        "        print(i*batch_size)\n",
        "        activations = ema_vae.encoder.forward(data_input)\n",
        "        px_z, stats = ema_vae.decoder.forward(activations, get_latents=True)\n",
        "        #recons = ema_vae.decoder.out_net.sample(px_z)\n",
        "        batch_latent = []\n",
        "        for i in range(num_latents):\n",
        "            batch_latent.append(stats[i]['z'].cpu().numpy().reshape(len(data_input),-1))\n",
        "        train_latents.append(np.hstack(batch_latent))\n",
        "train_latents = np.concatenate(train_latents)\n",
        "\n",
        "np.savez(\"data/extracted_features/subj{:02d}/nsd_vdvae_features_{}l.npz\".format(sub,num_latents),train_latents=train_latents,test_latents=test_latents)\n",
        "\n"
      ],
      "metadata": {
        "id": "y3tT8Z2fEMk5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}